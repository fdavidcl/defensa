<!DOCTYPE html>
<html lang=es-es>
  <meta charset=utf-8>
  <title>Mejoras en tratamiento de problemas de clasificación con modelos basados en autoencoders</title>
  <meta name=viewport content="width=device-width">
  <meta name="duration" content="45" />
  <link rel=stylesheet href="simple.css">
  <script src="b6plus.js"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Fira+Code&family=Rubik:ital,wght@0,400;0,600;1,400;1,600&family=Source+Sans+Pro:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">


<!--
  Slide transitions =========================  
fade-in
    The new slide appears faint at first and gets more opaque until it completely obscures the previous slide.
slide-in
    The new slide moves in from the left, while the previous slide moves back to the left.
move-left
    The new slides move in from the right while the old slide moves out to the left.
move-up
    The old slide moves up and the new slide moves in from the bottom.
flip-up
    A 3D effect: the bottom of the old slide is lifted up and the slide is turned over to reveal the new slide on its back side.
flip-left
    Another 3D effect, but in this case the right side of the slide is lifted up and the slide is flipped over to the left, revealing the new slide on the back side.
center-out
    A small circle appears in the middle of the old slide that reveals the new slide. The circle grows until it covers the whole slide.
wipe-left
    The new slide moves in from the right, until it covers the old slide.
zigzag-left
    A zigzag pattern moves in from the right. To the left is the old slide, to the right the new one.
zigzag-right
    A zigzag pattern moves in from the left. To the left is the new slide, to the right the old one.
cut-in
    The new slide moves in from the top left and covers the old slide. 
-->


 <body class="fade-in hidemouse=1.5">

  <div class=progress></div> <!-- progress bar -->

  <section role=region aria-live=assertive>
    <!-- What a screen reader should say on leaving slide mode,
	 instead of the default ‘Stopped.’ -->
    Leaving presentation mode.
  </section>

  <section class="comment small">

    Para iniciar la presentación, haz <a href="?full">clic aquí</a> o <b>doble clic</b> en cualquiera de las diapositivas. Para navegar por las diapositivas, puedes utilizar las flechas del teclado.
    <p>
      Esta presentación ha sido compuesta utilizando el <a href="https://www.w3.org/Talks/Tools/b6plus/">motor B6+ del W3C</a>, con scripts y estilos modificados por David Charte. Consulta el <a href="https://github.com/fdavidcl/defensa">código fuente en GitHub</a>.
    </p>
  </section>

  <section class="cover slide clear titleslide flex" id=cover>
    <div class="left-side vertical-logo">
        <span></span>
        <img src="images/logo_neg.png">
    </div>
    <div class="right-side">
      <img class="cover" src="images/fondo_portada.png"
      alt="Abstract nodes and connections" />
      <h1>
        Mejoras en tratamiento de <br>
        <span class="larger">problemas de clasificación</span><br>
        con modelos basados en <br>
        <span class="largest"><i>autoencoders</i></span>
      </h1>
      <p class="subtitle">Tesis para la obtención del título de doctor por
        la Universidad de Granada</p>
      <p class="institution">Programa de Doctorado en Tecnologías de la
        Información y la Comunicación<br>&nbsp;</p>
      <p class="author">Francisco David Charte Luque
        <a href="mailto:bert@w3.org" >&lt;fdavidcl@ugr.es&gt;</a></p>
      <p class="supervisors">
        <span class="subtitle">Directores:</span><br>
          Francisco Herrera Triguero<br>
          Francisco Charte Ojeda
      </p>
      <p class=note>6 de julio de 2022<br>
    </div>
  </section>

  <section class="slide clear">
    <h1>Índice</h1>
    <ol class="maketoc"></ol>
  </section>

  <section class="cover slide clear " id="intro">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <h1>Introducción</h1>
  </section>

  <section class="slide">
    <h1>Contexto</h1>
    <ul class="incremental">
        <li>Incremento en la recopilación de datos, su variedad y diversidad de fuentes</li>
        <li>Incremento en la recopilación de datos, su variedad y diversidad de fuentes</li>
        <li>Incremento en la recopilación de datos, su variedad y diversidad de fuentes</li>
    </ul>
  </section>

  
  <section id="motivación" class="slide section level2">
    <h1>Motivación</h1>
    <ul class="incremental">
        <li>¿Cómo se realiza aprendizaje de representaciones mediante modelos
            neuronales profundos?</li>
        <li>¿Qué beneficios se pueden obtener transformando datos a una
            representación apropiada?</li>
        <li>¿Se puede inducir un comportamiento específico en la transformación,
            como separación de clases?</li>
    </ul>
    <p>Este es un párrafo normal de texto</p>
    <p><span class="math display">$$\alpha=\sum_{p=0}^ne^{i\pi}$$</span></p>
    <p class="box">Esta es una caja con texto bastante largo para que ocupe varias líneas. Esta es una caja con texto bastante largo para que ocupe varias líneas. Esta es una caja con texto bastante largo para que ocupe varias líneas. Esta es una caja con texto bastante largo para que ocupe varias líneas</p>
  </section>
  <section class="slide section level2">
      <h1>Objetivos</h1>
      <ul class="incremental">
          <li>Estudio teórico y producción de recursos sobre <i>autoencoders</i>
          <li>Desarrollo de implementaciones de <i>autoencoders</i> accesibles
          <li>Exploración de aplicaciones de los modelos basados en <i>autoencoders</i> y de problemas supervisados donde pueden tener potencial
          <li>Diseño de soluciones basadas en <i>autoencoders</i> para el tratamiento de problemas supervisados
      </ul>
  </section>
  <section class="slide section level2" id="quees">
      <h1>¿Qué es un <i>autoencoder</i>?</h1>
      <video src="media/videos/scene/720p30/CreateNet.mp4" onclick="this.paused?this.play():this.pause()" muted preload="auto"></video>
  </section>


  <section class="slide cover clear" id="a1s1">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <div>
      <div class="flex">
        <h1>Tutorial práctico sobre autoencoders</h1>
      </div>
      <blockquote>
        Charte, D., Charte, F., García, S., del Jesus, M. J., & Herrera, F. (2018). A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines. <i>Information Fusion</i>, 44, 78-96.
      </blockquote>
      <!--ul>
        <li>Taxonomía</li>
        <li>Variantes</li>
        <li>Aplicaciones</li>
      </ul-->
    </div>
    <img class="preview" src="images/paper1.png">
  </section>

  <section class="slide" id="a1s2">
    <h1>Introducción</h1>
    <ul>
      <li><b>Fusión de características</b>: combinar variables para mejorar el aprendizaje, eliminar información redundante e irrelevante</li>
      <li><b>Autoencoders</b>: mecanismos de fusión de características basados en aprendizaje profundo</li>
    </ul>
  </section>

  <section class="slide" id="a1s3">
    <h1>Taxonomía</h1>
    <img src="images/taxonomy.png">
    <!-- <iframe src="assets/taxonomy.pdf#toolbar=0"></iframe> -->
  </section>

  <section class="slide" id="a1s4">
    <h1>Reducción de dimensionalidad</h1>
    <h3>Autoencoder básico</h3>
    <ul>
      <li>Encoder: \(y = f(x) = s_1(W^{(1)}x+b^{(1)})\)</li>
      <li>Decoder: \(x \approx g(y) = s_2(W^{(2)}y+b^{(2)})\)</li>
      <li>Función objetivo: \(\mathcal J(W,b;S)= \sum_{x \in S} \mathcal L(x, (g\circ f)(x))\)
        donde \(\mathcal L\) es <b>error reconstrucción</b>, e.g. \(\mathcal L_{\mathrm{MSE}}(u, v)=\left\lVert u - v\right\rVert_2^2~\)</li>
    </ul>
    <div class="flex">
      <div>
        <h3>Variaciones</h3>
        <ul>
          <li>Deep</li>
          <li>Stacked</li>
        </ul>
      </div>
      <div>
        <h3>Dominio específico</h3>
        <ul>
          <li>Convolutional</li>
          <li>LSTM</li>
        </ul>
      </div>
    </div>
  
  </section>

  <section class="slide" id="a1s5">
    <h1>Regularización</h1>
    <div class="flex">
      <div>
        <h3>Sparse autoencoder</h3>

        Penaliza las activaciones frecuentes de neuronas:
        $$\Omega_{\mathrm{SAE}}(W,b;S)=\sum_{i=1}^c \mathrm{KL}(\rho\Vert \hat\rho_i)~$$
      </div>
      <div></div>
    </div>
    <h3>Contractive autoencoder</h3>
    Penaliza la sensibilidad a pequeños cambios en la entrada:
    $$  \Omega_{\mathrm{CAE}}(W,b;S) = \sum_{x\in S}\left\lVert J_f(x) \right\rVert_F^2;~\left\lVert J_f(x) \right\rVert_F^2=
  \sum_{j=1}^d\sum_{i=1}^c \left(\frac{\partial f_i}{\partial x_j}\left(x\right)\right)^2~.$$
  </section>

  <section class="slide" id="a1s6">
    <h1>Tolerancia a ruido</h1>
    <div class="">
      <div>
        <h3>Denoising autoencoder</h3>
        Aprende a restaurar <strong>instancias ruidosas</strong>

        $$\mathcal J_{\mathrm{DAE}}(W,b;S)= \sum_{x\in S}\mathbb E_{\tilde x \sim q(\tilde x \vert x)} \left[\mathcal L(x, (g\circ f)(\tilde x))\right]$$


      </div>
      <div>
        <h3>Robust autoencoder</h3>
        <strong>Correntropía</strong>: función objetivo menos sensible a ruido
        $$\mathcal L_{\mathrm{MCC}}(u, v)=-\sum_{k=1}^d\mathcal K_{\sigma}(u_k-v_k),\text{ donde } \mathcal K_{\sigma}(\alpha)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{\alpha^2}{2\sigma^2}\right),$$
      
y \(\sigma\) es parámetro de \(\mathcal K\).
      </div>
    </div>
  </section>

  <section class="slide" id="a1s7">
    <h1>Modelos generativos</h1>
    <h3>Variational autoencoder</h3>
    <ul><li>Enfoque de inferencia variacional mediante <i>reparameterization trick</i></ul>
    <h3>Adversarial autoencoder</h3>
    <ul><li>Inspirados por Generative Adversarial Networks</li></ul>
  </section>

  <section class="slide" id="a1s8">
    <h1>Comparación con otras técnicas</h1>
    <ul class="incremental">
      <li><b>PCA</b>: Idéntica solución al AE lineal optimizando ECM</li>
      <li>Análisis factorial supone variables (factores) ocultas, como el VAE</li>
      <li>LDA es supervisado, busca mejor separación de clases</li>
      <li>Kernel PCA varía según el kernel escogido</li>
      <li>Multidimensional scaling y Sammon mapping buscan preservar distancias relativas</li>
      <li>Isomap y LLE mantienen estructura local, similar a Contractive AE</li>
      <li>Restricted Boltzmann Machine es un modelo gráfico alternativo a AE para <i>pretraining</i></li>
    </ul>
  </section>

  <section class="slide" id="a1s9">
    <h1>Guía de diseño de autoencoders</h1>
    <img src="images/guidelines.png">
  </section>

  <section class="slide cover clear" id="a4s1">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <div>
      <h1>Aplicaciones de  autoencoders en aprendizaje de representaciones</h1>
      <blockquote>
        Charte, D., Charte, F., del Jesus, M. J., & Herrera, F. (2020). An analysis on the use of autoencoders for representation learning: Fundamentals, learning task case studies, explainability and challenges. <i>Neurocomputing</i>, 404, 93-107.
      </blockquote>
    </div>
    <img class="preview" src="images/paper4.png">
  </section>

  <section class="slide cover clear" id="a2s1">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <div>
      <h1>Software para autoencoders en R: Ruta</h1>
      <blockquote>
        Charte, D., Herrera, F., & Charte, F. (2019). Ruta: Implementations of neural autoencoders in R. <i>Knowledge-Based Systems</i>, 174, 4-8.
      </blockquote>
    </div>
    <img class="preview" src="images/paper2.png">
  </section>

  <section class="slide" id="a2s2">
    <h1>Software previo para AEs</h1>
    <div class="flex">
      <div>
        <b>Bibliotecas de cálculo tensorial</b> (PyTorch, Tensorflow)
        <ul>
          <li>Barrera de acceso: APIs complejas</li>
          <li>Extracción de características difícil</li>
          <li>Implementación manual de muchas funciones</li>
        </ul><p></p>
        <b>Implementaciones de autoencoders</b>
        <ul>
          <li>Autoencoder (R): básico/sparse</li>
          <li>SAENET (R): sparse/stacked</li>
          <li>H2O (Java/R): básico</li>
          <li>yadlt (python): básico/denoising</li>
        </ul>
      </div>
      <img src="images/tensorflowae.png" style="height: 20em">
    </div><p></p>

    <div class="box">Es necesaria una implementación <b>accesible y versátil</b> de autoencoders</div>
  </section>

  <section class="slide" id="a2s3">
    <h1>Arquitectura y funcionalidad</h1>
    <h3>Clases definidas</h3>
    <ul>
      <li><code>ruta_autoencoder</code>: modelo de aprendizaje <br> puede <strong>entrenarse, codificar y reconstruir</strong></li>
      <li><code>ruta_network</code>: estructura de capas neuronales <br>pueden <strong>concatenarse</strong></li>
      <li><code>ruta_loss</code>: función a optimizar (interna a Keras o externa: correntropía)</li>
      <li><code>ruta_noise</code>: un tipo de ruido aplicable a datos de entrada</li>
    </ul>
    <h3>Funcionalidades</h3>
    <ul>
      <li>Definir y personalizar aspectos de un modelo AE</li>
      <li>Entrenar diferentes variantes de AE según varias funciones objetivo</li>
      <li>Codificar y reconstruir datos</li>
      <li>Evaluar un modelo con métricas de calidad</li>
      <li>Muestrear modelos generativos (variacionales)</li>
    </ul>

  </section>

  <section class="slide" id="a2s4">
    <h1>Detalles de implementación</h1>
    <ul>
      <li>Lenguaje: <b>R</b></li>
      <li>Biblioteca de cálculo: <b>Tensorflow/Keras</b></li>
      <li>Código fuente: <a href="https://github.com/fdavidcl/ruta">github.com/fdavidcl/ruta</a></li>
      <li>Documentación: <a href="https://ruta.software">ruta.software</a></li>
    </ul>
    <div class="flex">
      <div>

        <h3>Variantes de AE implementadas</h3>
        <ul>
          <li>básico</li>
          <li>sparse</li>
          <li>contractive</li>
          <li>denoising</li>
          <li>robust</li>
          <li>variational</li>
        </ul>
      </div>
      <div>
        <h3>Tipos de capas</h3>
        <ul>
          <li>densas</li>
          <li>convolucionales (1D, 2D, 3D)</li>
        </ul>
      </div>
    </div>

  </section>

  <section class="slide" id="a2s5">
    <h1>Ejemplos de uso</h1>
    <h3>Entrenamiento y codificación</h3>
    <pre><code class="language-r">encoded <- iris[, 1:4] %>% as.matrix() %>% 
  autoencode(2, "robust")</code></pre>
    <h3>Definición de una red, reconstrucción, evaluación</h3>
    <pre><code class="language-r">learner <- autoencoder_sparse(
  input() + dense(3, "tanh") + output(),
  "mean_squared_error"
)
model <- train(learner, train_x, epochs = 200)
reconstructions <- reconstruct(model, test_x)
evaluate_mean_squared_error(model, test_x)</code></pre>
  </section>

  <section class="slide" id="a2s6">
    <h1>Ejemplo AE variacional</h1>
    <pre><code class="language-r">network <-
  input() +
  dense(256, "elu") +
  variational_block(10, seed = 42) +
  dense(256, "elu") +
  output("sigmoid")
learner <- autoencoder_variational(network, 
  loss = "binary_crossentropy")
model <- train(learner, x_train, epochs = 10)

samples <- model %>% generate(dimensions = c(8, 5), 
  side = 6, fixed_values = 0.99)
plot_matrix(samples)</code></pre>
<img src="images/rutavariational.png" alt="Muestreo de dígitos de la codificación aprendida desde MNIST con un autoencoder variacional" style="height: 6em">
  </section>


  <section class="slide cover clear" id="a3s1">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <div>
      <h1>Problemas no estándares en aprendizaje supervisado</h1>
      <blockquote>
        Charte, D., Charte, F., García, S., & Herrera, F. (2019). A snapshot on nonstandard supervised learning problems: taxonomy, relationships, problem transformations and algorithm adaptations. <i>Progress in Artificial Intelligence</i>, 8(1), 1-14.
      </blockquote>
    </div>
    <img class="preview" src="images/paper3.png">
  </section>

  <section class="slide cover clear" id="a5s1">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <div>
      <h1>Nuevos modelos para reducir complejidad</h1>
      <blockquote>
        Charte, D., Charte, F., & Herrera, F. (2021). Reducing data complexity using autoencoders with class-informed loss functions. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>.
      </blockquote>
    </div>
    <img class="preview" src="images/paper5.png">
  </section>

  <!-- dar más bombo al último paper!! -->

  <section class="slide cover clear" id="conclusiones">
    <img class="cover" src="images/fondo_portada.png"
    alt="Abstract nodes and connections" />
    <h1>Comentarios finales</h1>
  </section>

  <script>
    (function() {
      let toc_slide = document.querySelector(".maketoc")
      let current_section = ""
      let current_section_id = ""
      let slides = document.querySelectorAll(".slide")

      for (let i = 0; i < slides.length; ++i) {
        if (slides[i].classList.contains("cover") && !slides[i].classList.contains("titleslide")) {
          current_section = slides[i].querySelector("h1").textContent;
          current_section_id = slides[i].id;
          toc_slide.insertAdjacentHTML('beforeend', `<li><a class=internal href="#${current_section_id}">${current_section}</a></li>`)
        } else if (!slides[i].classList.contains("clear")) {
          slides[i].insertAdjacentHTML('beforeend', `<footer><a class=internal href="#${current_section_id}">${current_section}</a></footer>`)
        }
      }
    })()
  </script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js" integrity="sha384-X/XCfMm41VSsqRNQgDerQczD69XqmjOOOwYQvr/uuC+j4OPoNhVgjdGFwhvN02Ja" crossorigin="anonymous"></script>

  <!-- automatically render math in text elements -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>
  
      <link rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css">
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
  
  <script>window.addEventListener("load", function() {hljs.highlightAll();})</script>
 </body>
</html>
